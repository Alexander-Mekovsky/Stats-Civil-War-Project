---
title: "R Notebook"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---
loadding the libraries and load the data 

```{r reading_data}
suppressMessages(library(dplyr))
suppressMessages(library(tidyverse))

library(dplyr)
library(tidyr)
library(ggplot2)

df <- read_csv("data/civilWar.csv")
# summarize the data to check for ouliers 
summary(df)
#check fi there is nas in the dataset
sum(is.na(df))
#The data do not hace any outlier

head(df)
```


# Creating an histogram of the data to check on the data distribution 

 The histogram shows Right-skewed Schooling with extreme range.I personaly request to tramsform this predictor however it will depend to the model performence result.
```{r creating_histogram}
df_cleaned <- df %>%
  select(-c(dominance, civil.war)) %>% # removing th ecategorical data 
  pivot_longer(
    cols = everything(),
    names_to = "variable",
    values_to = "value"
  )

# Assuming df is your original dataframe
df_cleaned <- df %>%
  select(-c(dominance, civil.war)) %>%
  pivot_longer(
    cols = everything(),
    names_to = "variable",
    values_to = "value"
  )

# Creating histograms 

plot <- ggplot(df_cleaned, aes(x = value,fill = variable)) + 
  geom_histogram(bins = 10) + 
  facet_wrap(~ variable, scales = "free_x") +
  theme_minimal() +
  theme(
    
    panel.grid.major = element_blank(), # remove major grid lines
    panel.grid.minor = element_blank()  # remove minor grid lines
  ) +
  labs(x = NULL, y = "Frequency") +
	theme(legend.title = element_blank(),legend.position = "top",legend.direction = "horizontal")

print(plot)



```


Transforming the predictor variable "Schooling "

```{r}
df$schooling <- sqrt(df$schooling)		 # transforming the scholing predictor
df_cleaned <- df %>%
  select(-c(dominance, civil.war)) %>%
  pivot_longer(
    cols = everything(),
    names_to = "variable",
    values_to = "value"
  )

# Creating histograms 

plot <- ggplot(df_cleaned, aes(x = value,fill = variable)) + 
  geom_histogram(bins = 10) + 
  facet_wrap(~ variable, scales = "free_x") +
  theme_minimal() +
  theme(
    
    panel.grid.major = element_blank(), # remove major grid lines
    panel.grid.minor = element_blank()  # remove minor grid lines
  ) +
  labs(x = NULL, y = "Frequency") +
	theme(legend.title = element_blank(),legend.position = "top",legend.direction = "horizontal")

print(plot)

```

# Target (categorical varible) Variable Distribution analysis

```{r target-distribution}
df_targeted <- df %>% 
  select(civil.war, dominance) %>% 
  pivot_longer(
    names_to = "variable", 
    values_to = "value", 
    cols = everything()
  )

ggplot(df_targeted) +
  geom_bar(aes(x = variable, fill = value)) +
  scale_fill_manual(values = c("NO" = "green", "YES" = "red")) +
  ggtitle("Distribution of Civil War Occurrence and Dominance") +
  xlab("Variables") +
  ylab("Count") +
  theme(
    panel.grid.major = element_blank(), # remove major grid lines
    panel.grid.minor = element_blank(), # remove minor grid lines
    panel.background = element_blank(), # remove background
    axis.line = element_line(color = "black"), # add axis lines
    legend.position = c(0.6, 0.5),
    legend.title = element_blank() # remove legend title
  )


```

# Pairplot of Numerical Features
In this plot, we are analyzing the correlation between pairs of predictors. A strong correlation indicates a high probability of col linearity between the predictors, which would need to be addressed.

The pair plot below shows that there is no strong correlation between the predictors, indicating an absence of collinearity or redundancy among the predictors in the dataset.

```{r pairplot}
pairs(df[, c("exports", "schooling", "growth", "concentration", "lnpop", "fractionalization")],
      main = "Pairplot of Numerical Features",
      col = ifelse(df$civil.war == "YES", "red", "blue"))
```

# Correlation Heatmap

similary the corplot is relating different predictors and can assist in verfying hte colinearility, an looks like a best way to assess the colineality in data sets.

```{r correlation-heatmap}
library(corrplot)
num_features <- df[, c('exports', 'schooling', 'growth', 'concentration', 'lnpop', 'fractionalization')]
cor_matrix <- cor(num_features, use = "complete.obs")
corrplot(cor_matrix, method = "circle", type = "lower", tl.col = "black", tl.srt = 45)
```

# Split data into training and test dataset

```{r split-dataset}
df$civil.war <- factor(df$civil.war, levels = c("NO", "YES"))
df$dominance <- factor(df$dominance, levels = c("NO", "YES"))

set.seed(123)
train_idx <- sample(nrow(df),round(0.7*nrow(df)))
train <- df[train_idx, ]
test <- df[-train_idx, ]
```
# Logistic regression
```{r logistic-regression}
suppressMessages(library(pROC))

log_mdl <- glm(civil.war ~ ., data = train, family = binomial)
log_probs <- predict(log_mdl, newdata = test, type = "response")
roc_log <- roc(test$civil.war, log_probs)
auc_log <- auc(roc_log)
threshold_log <- as.numeric(coords(roc_log, "best", ret = "threshold", best.method = "youden")[1])

log_pred_class <- ifelse(log_probs > threshold_log, "YES", "NO")
# Missclassification rate
mcr_log <- mean(log_pred_class != test$civil.war)
```
```{r summary logistic regression}
summary(log_mdl)
```
# Disaply logistic regression results
```{r results}
cat("AUC (logistic regression):", round(auc_log, 3), "\n")
cat("MCR (logistic regression):", round(mcr_log, 3), "\n")
```
# Show the confusion matrix
```{r confusion-matrix}
log_conf_matrix <- table(Predicted = log_pred_class, Actual = test$civil.war)
print(log_conf_matrix)
```

# Calculate metrics
```{r metrics}
conf_matrix <- log_conf_matrix
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- conf_matrix["YES", "YES"] / sum(conf_matrix["YES", ])
recall <- conf_matrix["YES", "YES"] / sum(conf_matrix[, "YES"])
f1_score <- 2 * (precision * recall) / (precision + recall)

cat("Logistic regression:","\n","Accuracy:", round(accuracy, 3), "\n")
cat("Precision:", round(precision, 3), "\n")
cat("Recall:", round(recall, 3), "\n")
cat("F1 Score:", round(f1_score, 3), "\n")
```

## Scaled Logistic 

Scale the numerical variables and check the coefficients to find important predictors.

```{r}
df.train <- train

# Standardize numerical variables
df.train$exports <- scale(df.train$exports)
df.train$schooling <- scale(df.train$schooling)
df.train$growth <- scale(df.train$growth)
df.train$concentration <- scale(df.train$concentration)
df.train$lnpop <- scale(df.train$lnpop)
df.train$fractionalization <- scale(df.train$fractionalization)

# Fit a new logistic regression model
model_scaled <- glm(civil.war ~ ., data = df.train, family = binomial)

# Summary of the scaled model
summary(model_scaled)
```
```
'schooling' and 'lnpop' here are important.
```


## Random Forest

```{r}
set.seed(408)

suppressMessages(library(randomForest))
suppressMessages(library(pROC))

df.train <- train

# AUC value
rf.out = randomForest(civil.war ~ ., data=df.train,importance=TRUE)
out.pred = predict(rf.out,newdata=test,type="prob")[,2]
roc_obj <- roc(test$civil.war, out.pred)  
auc_value <- auc(roc_obj)
print(paste("Random Forest AUC:", round(auc_value, 3)))

# Youden’s J
optimal_threshold <- coords(roc_obj, "best", ret="threshold", best.method="youden")
print(paste("Random Forest Optimal Threshold:", round(optimal_threshold, 3)))

# MCR and confusion matrix
resp.pred <- ifelse(out.pred >= as.numeric(optimal_threshold), "YES","NO")
resp.test = test$civil.war
cat('Random Forest MCR: ',mean(resp.pred!=resp.test),'\n') 
tab <- table(resp.pred,resp.test)
print(tab)
```


## Importance plot

Create an importance plot to see the important variables given by our random forest model.

```{r}
varImpPlot(rf.out,type=1)
```
```
'lnpop' is important here again.
```

## Trees

Try (pruned) trees to visuailize the classification process.

```{r}
library(rpart)

df.train <- train
df.test <- test

# AUC value
rpart.out <- rpart(civil.war~.,data=df.train)
resp.pred <- predict(rpart.out,newdata=df.test,type="prob")[,2]
roc_obj <- roc(df.test$civil.war, resp.pred)  
auc_value <- auc(roc_obj)
print(paste("Tree AUC:", round(auc_value, 3)))

# Youden’s J
optimal_threshold <- coords(roc_obj, "best", ret="threshold", best.method="youden")
print(paste("Tree Optimal Threshold:", round(optimal_threshold, 3)))

# MCR and confusion matrix
resp.pred <- ifelse(resp.pred >= as.numeric(optimal_threshold), "YES","NO")
resp.test = df.test$civil.war
cat('Tree MCR: ',mean(resp.pred!=resp.test),'\n') 
tab <- table(resp.pred,resp.test)
print(tab)
```

```{r}
# visualization
library(rpart.plot)

rpart.pruned <- prune(rpart.out,cp=0.03)
rpart.plot(rpart.pruned,extra=104)
```
```
We can draw a conclusion here that 'lnpop' is the most important variable here. As long as lnpop < 17, a civil war is almost impossible to occur(70% vs. 2%). This simple method of judgment can cover ～70% of the cases in our training set. 
```

## SVM

Try SVM.

```{r}
set.seed(408)

suppressMessages(library(e1071))

df.train <- train
df.test <- test

tune.out <- tune(svm, 
                 civil.war ~ ., 
                 data = df.train, 
                 kernel = "linear", 
                 ranges = list(cost = 10^seq(-2, 0, by = 0.1)),
                 probability = TRUE)
best.model <- tune.out$best.model
resp.pred <- predict(best.model, newdata = df.test, probability = TRUE)
prob.attr <- attr(resp.pred, "probabilities")
resp.prob <- prob.attr[, "YES"] 

# Compute AUC
roc_obj <- roc(df.test$civil.war, resp.prob)
auc_value <- auc(roc_obj)
print(paste("SVM (Linear Kernel) AUC:", round(auc_value, 3)))

# Youden's J for optimal threshold
optimal_threshold <- coords(roc_obj, "best", ret = "threshold", best.method = "youden")
print(paste("SVM Optimal Threshold:", round(optimal_threshold, 3)))

# MCR and confusion matrix
final_predictions <- ifelse(resp.prob >= as.numeric(optimal_threshold), "YES", "NO")
cat("SVM MCR:", mean(final_predictions != df.test$civil.war), "\n")
conf_matrix <- table(Predicted = final_predictions, Actual = df.test$civil.war)
print(conf_matrix)
```